BEGIN:VCALENDAR
BEGIN:VEVENT
SUMMARY:Call Scheduling to Reduce Response Time of a FaaS System\, Paweł 
 Żuk
DTSTART;TZID=Europe/Berlin;VALUE=DATE-TIME:20220907T160000
DTEND;TZID=Europe/Berlin;VALUE=DATE-TIME:20220907T163000
DESCRIPTION:In an overloaded FaaS cluster\, individual worker nodes strain
  under lengthening queues of requests. Although the cluster might be event
 ually horizontally-scaled\, adding a new node takes dozens of seconds. As 
 serving applications are tuned for tail serving latencies\, and these grea
 tly increase under heavier loads\, the current workaround is resource over
 -provisioning. In fact\, even though a service can withstand a steady load
  of e.g. 70% CPU utilization\, the autoscaler is triggered at e.g. 30-40% 
 (thus the service uses twice as many nodes as it would be needed). We prop
 ose an alternative: a worker-level method handling heavy load without incr
 easing the number of nodes. FaaS executions are not interactive\, compared
  to\, e.g.\, text editors: end-users take no advantage of when CPU is assi
 gned to processes often\, yet for short periods. Inspired by scheduling me
 thods for High Performance Computing\, we take a radical step of replacing
  the classic OS preemption by (1) queuing requests based on their historic
 al characteristics\; (2) once a request is being processed\, setting its C
 PU limit to exactly one core (with no CPU oversubscription). We extend Ope
 nWhisk and measure the efficiency of the proposed solutions\, based on SeB
 S benchmark. In a loaded system\, our method decreases the average respons
 e time by a factor of 4. The improvement is even higher for shorter reques
 ts\, as the average stretch is decreased by a factor of 18. This leads us 
 to show that we can provide better response-time statistics with 3 machine
 s compared to a 4-machine baseline.
END:VEVENT
END:VCALENDAR
